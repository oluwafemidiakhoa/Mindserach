{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6hy3v0oQbHIGqpBuJ0t5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oluwafemidiakhoa/Mindserach/blob/master/ETF_and_Mutual_Fund_Search_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio transformers pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkQC6fSY8jQF",
        "outputId": "4c2ba7a9-faf7-435b-ddf3-f1a9dc36f1a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.8 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.31.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's unzip the file using Python to check its contents\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded zip file and extraction directory\n",
        "zip_file_path = '/content/Fiance_1.zip'\n",
        "extracted_dir_path = '/content//extracted_data/'\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "# List the contents of the extracted directory to see the files\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "extracted_files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBoabErgz49t",
        "outputId": "e09a51e6-8c25-490d-a599-a1a7f9706a99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ETFs.csv',\n",
              " 'MutualFund prices - F-K.csv',\n",
              " 'MutualFund prices - Q-Z.csv',\n",
              " 'MutualFunds.csv',\n",
              " 'MutualFund prices - L-P.csv',\n",
              " 'ETF prices.csv',\n",
              " 'MutualFund prices - A-E.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for data handling and transformers\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, pipeline\n",
        "\n",
        "# Load ETF and Mutual Fund data\n",
        "etfs_df = pd.read_csv('/content/extracted_data/ETFs.csv')\n",
        "mutual_funds_df = pd.read_csv('/content/extracted_data/MutualFunds.csv')\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Define a classifier for detecting unsafe financial advice (toxicity detection)\n",
        "toxicity_classifier = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
        "\n",
        "# Step 4: Load a pre-trained language model and tokenizer (using GPT-2 as an example)\n",
        "model_name = \"gpt2\"  # Use a valid public model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Step 5: Define the function to search for ETFs or Mutual Funds based on refined user query\n",
        "def search_financial_data(query, etf_df, mf_df, filters=None):\n",
        "    # Initialize result\n",
        "    result = None\n",
        "\n",
        "    # Check if the query relates to ETFs\n",
        "    if \"ETF\" in query:\n",
        "        # Start with basic symbol or name matching\n",
        "        result = etf_df[\n",
        "            etf_df['fund_symbol'].str.contains(query.split()[-1], case=False) |\n",
        "            etf_df['fund_short_name'].str.contains(query.split()[-1], case=False, na=False) |\n",
        "            etf_df['fund_long_name'].str.contains(query.split()[-1], case=False, na=False)\n",
        "        ]\n",
        "\n",
        "        # Apply additional filters if provided\n",
        "        if filters:\n",
        "            # Step 5.1: Filter by category (e.g., Large Blend, Small Value)\n",
        "            if 'fund_category' in filters:\n",
        "                result = result[result['fund_category'].str.contains(filters['fund_category'], case=False, na=False)]\n",
        "\n",
        "            # Step 5.2: Filter by minimum yield (e.g., minimum dividend yield)\n",
        "            if 'min_yield' in filters:\n",
        "                result = result[result['fund_yield'] >= filters['min_yield']]\n",
        "\n",
        "            # Step 5.3: Filter by minimum return in 1 year\n",
        "            if 'min_return_1year' in filters:\n",
        "                result = result[result['fund_return_1year'] >= filters['min_return_1year']]\n",
        "\n",
        "            # Step 5.4: Filter by specific top holdings (e.g., ETFs holding Apple stock)\n",
        "            if 'top_holdings' in filters:\n",
        "                result = result[result['top10_holdings'].str.contains(filters['top_holdings'], case=False, na=False)]\n",
        "\n",
        "            # Step 5.5: Filter by fund size (e.g., Large, Medium, Small cap)\n",
        "            if 'size_type' in filters:\n",
        "                result = result[result['size_type'].str.contains(filters['size_type'], case=False, na=False)]\n",
        "\n",
        "            # Step 5.6: Filter by region (e.g., US, Europe, Asia)\n",
        "            if 'region' in filters:\n",
        "                result = result[result['region'].str.contains(filters['region'], case=False, na=False)]\n",
        "\n",
        "            # Step 5.7: Filter by minimum return over 3 years\n",
        "            if 'min_return_3years' in filters:\n",
        "                result = result[result['fund_return_3years'] >= filters['min_return_3years']]\n",
        "\n",
        "            # Step 5.8: Filter by minimum return over 5 years\n",
        "            if 'min_return_5years' in filters:\n",
        "                result = result[result['fund_return_5years'] >= filters['min_return_5years']]\n",
        "\n",
        "            # Step 5.9: Filter by minimum return over 10 years\n",
        "            if 'min_return_10years' in filters:\n",
        "                result = result[result['fund_return_10years'] >= filters['min_return_10years']]\n",
        "\n",
        "            # Step 5.10: Filter by risk metrics like Sharpe Ratio over 5 years\n",
        "            if 'min_sharpe_ratio_5years' in filters:\n",
        "                result = result[result['fund_sharpe_ratio_5years'] >= filters['min_sharpe_ratio_5years']]\n",
        "\n",
        "        # Return results or message if no match found\n",
        "        if result.empty:\n",
        "            return \"No matching ETFs found.\"\n",
        "        return result.to_dict(orient='records')\n",
        "\n",
        "    # Step 6: Check if the query relates to Mutual Funds (similar filters can be applied)\n",
        "    elif \"Mutual Fund\" in query:\n",
        "        result = mf_df[\n",
        "            mf_df['fund_symbol'].str.contains(query.split()[-1], case=False) |\n",
        "            mf_df['fund_short_name'].str.contains(query.split()[-1], case=False, na=False) |\n",
        "            mf_df['fund_long_name'].str.contains(query.split()[-1], case=False, na=False)\n",
        "        ]\n",
        "\n",
        "        # Apply similar filters for Mutual Funds (if needed)\n",
        "        if filters:\n",
        "            # Mutual fund filters can be added here\n",
        "            pass\n",
        "\n",
        "        if result.empty:\n",
        "            return \"No matching Mutual Funds found.\"\n",
        "        return result.to_dict(orient='records')\n",
        "\n",
        "    return \"Query unclear, please specify whether you are searching for ETFs or Mutual Funds.\"\n",
        "\n",
        "# Step 7: Define the backtracking mechanism with classifier and financial data\n",
        "def generate_with_backtracking(prompt, model, tokenizer, classifier, etf_df, mf_df, filters=None):\n",
        "    # Step 7.1: Search financial data first if relevant to prompt\n",
        "    financial_results = search_financial_data(prompt, etf_df, mf_df, filters)\n",
        "\n",
        "    if financial_results != \"Query unclear, please specify whether you are searching for ETFs or Mutual Funds.\":\n",
        "        return financial_results  # Return financial data if found\n",
        "\n",
        "    # Step 7.2: Otherwise, continue to generate text and check for unsafe responses\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs['input_ids'], max_new_tokens=50, do_sample=True)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "\n",
        "    # Step 7.3: Use classifier to detect unsafe content\n",
        "    classification = classifier(generated_text)\n",
        "\n",
        "    # If unsafe content is detected, backtrack and generate a safe response\n",
        "    if classification[0]['label'] == 'toxic' and classification[0]['score'] > 0.5:  # Threshold for toxicity\n",
        "        reset_point = generated_text.find(classification[0]['label'])\n",
        "        safe_text = generated_text[:reset_point]\n",
        "        safe_text += \"[RESET] This response has been adjusted for safety.\"  # Simulate reset and safe generation\n",
        "        return safe_text\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Step 8: Define the query with refined filters\n",
        "prompt = \"Search for ETF SPY\"\n",
        "filters = {\n",
        "    'fund_category': 'Large Blend',       # Filter by fund category\n",
        "    'min_yield': 0.01,                    # Minimum yield of 1%\n",
        "    'min_return_1year': 0.1,              # Minimum return of 10% in 1 year\n",
        "    'top_holdings': 'Apple',              # ETFs holding Apple\n",
        "    'size_type': 'Large',                 # Large cap funds\n",
        "    'region': 'US',                       # US-based ETFs\n",
        "    'min_return_3years': 0.05,            # Minimum 5% return over 3 years\n",
        "    'min_sharpe_ratio_5years': 0.5        # Minimum Sharpe ratio of 0.5 over 5 years\n",
        "}\n",
        "\n",
        "# Step 9: Call the function with refined filters\n",
        "generated_response = generate_with_backtracking(prompt, model, tokenizer, toxicity_classifier, etfs_df, mutual_funds_df, filters)\n",
        "\n",
        "# Step 10: Display results in a table format if it's a financial query response\n",
        "if isinstance(generated_response, list):\n",
        "    df_display = pd.DataFrame(generated_response)\n",
        "    df_display = df_display[['fund_symbol', 'fund_long_name', 'region', 'currency', 'fund_category', 'fund_yield', 'top10_holdings', 'fund_return_1year', 'fund_return_5years']]\n",
        "\n",
        "    # Use pandas to display the DataFrame in a simple print format\n",
        "    print(df_display)\n",
        "else:\n",
        "    print(\"Generated Response with Backtracking: \", generated_response)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh7UIi6OzPN4",
        "outputId": "97a7b6e5-f49d-4973-978b-10d5daab520a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fund_symbol   fund_long_name region currency fund_category  fund_yield  \\\n",
            "0        SPYX  BFS Equity Fund     US      USD   Large Blend      0.0114   \n",
            "\n",
            "                                      top10_holdings  fund_return_1year  \\\n",
            "0  MSFT (\"Microsoft Corp\"): 0.0495, AMZN (\"Amazon...              0.409   \n",
            "\n",
            "   fund_return_5years  \n",
            "0               0.185  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Load ETF and Mutual Fund data\n",
        "etfs_df = pd.read_csv('/content/extracted_data/ETFs.csv')\n",
        "mutual_funds_df = pd.read_csv('/content/extracted_data/MutualFunds.csv')\n",
        "\n",
        "# Step 3: Define a classifier for detecting unsafe financial advice (toxicity detection)\n",
        "toxicity_classifier = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
        "\n",
        "# Step 4: Load a pre-trained language model and tokenizer (using GPT-2 as an example)\n",
        "model_name = \"gpt2\"  # Use a valid public model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Step 5: Define the function to search for ETFs or Mutual Funds based on refined user query\n",
        "def search_financial_data(query, etf_df, mf_df, filters=None):\n",
        "    # Initialize result\n",
        "    result = None\n",
        "\n",
        "    # Check if the query relates to ETFs\n",
        "    if \"ETF\" in query:\n",
        "        result = etf_df[\n",
        "            etf_df['fund_symbol'].str.contains(query.split()[-1], case=False) |\n",
        "            etf_df['fund_short_name'].str.contains(query.split()[-1], case=False, na=False) |\n",
        "            etf_df['fund_long_name'].str.contains(query.split()[-1], case=False, na=False)\n",
        "        ]\n",
        "\n",
        "        # Apply additional filters if provided\n",
        "        if filters:\n",
        "            if 'fund_category' in filters:\n",
        "                result = result[result['fund_category'].str.contains(filters['fund_category'], case=False, na=False)]\n",
        "            if 'min_yield' in filters:\n",
        "                result = result[result['fund_yield'] >= filters['min_yield']]\n",
        "            if 'min_return_1year' in filters:\n",
        "                result = result[result['fund_return_1year'] >= filters['min_return_1year']]\n",
        "            if 'top_holdings' in filters:\n",
        "                result = result[result['top10_holdings'].str.contains(filters['top_holdings'], case=False, na=False)]\n",
        "            if 'size_type' in filters:\n",
        "                result = result[result['size_type'].str.contains(filters['size_type'], case=False, na=False)]\n",
        "            if 'region' in filters:\n",
        "                result = result[result['region'].str.contains(filters['region'], case=False, na=False)]\n",
        "            if 'min_return_3years' in filters:\n",
        "                result = result[result['fund_return_3years'] >= filters['min_return_3years']]\n",
        "            if 'min_sharpe_ratio_5years' in filters:\n",
        "                result = result[result['fund_sharpe_ratio_5years'] >= filters['min_sharpe_ratio_5years']]\n",
        "\n",
        "        if result.empty:\n",
        "            return \"No matching ETFs found.\"\n",
        "        return result.to_dict(orient='records')\n",
        "\n",
        "    return \"Query unclear, please specify whether you are searching for ETFs or Mutual Funds.\"\n",
        "\n",
        "# Step 6: Define the backtracking mechanism\n",
        "def generate_with_backtracking(prompt, model, tokenizer, classifier, etf_df, mf_df, filters=None):\n",
        "    financial_results = search_financial_data(prompt, etf_df, mf_df, filters)\n",
        "\n",
        "    if financial_results != \"Query unclear, please specify whether you are searching for ETFs or Mutual Funds.\":\n",
        "        return pd.DataFrame(financial_results)  # Return financial data in table format\n",
        "\n",
        "    # Generate text using GPT-2 if no financial data found\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs['input_ids'], max_new_tokens=50, do_sample=True)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "\n",
        "    classification = classifier(generated_text)\n",
        "\n",
        "    if classification[0]['label'] == 'toxic' and classification[0]['score'] > 0.5:\n",
        "        reset_point = generated_text.find(classification[0]['label'])\n",
        "        safe_text = generated_text[:reset_point] + \"[RESET] This response has been adjusted for safety.\"\n",
        "        return safe_text\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Step 7: Define the function to be used in the Gradio interface\n",
        "def query_etfs(prompt, fund_category, min_yield, min_return_1year, top_holdings, size_type, region, min_return_3years, min_sharpe_ratio_5years):\n",
        "    filters = {\n",
        "        'fund_category': fund_category,\n",
        "        'min_yield': min_yield,\n",
        "        'min_return_1year': min_return_1year,\n",
        "        'top_holdings': top_holdings,\n",
        "        'size_type': size_type,\n",
        "        'region': region,\n",
        "        'min_return_3years': min_return_3years,\n",
        "        'min_sharpe_ratio_5years': min_sharpe_ratio_5years\n",
        "    }\n",
        "\n",
        "    return generate_with_backtracking(prompt, model, tokenizer, toxicity_classifier, etfs_df, mutual_funds_df, filters)\n",
        "\n",
        "# Step 8: Define the Gradio interface layout\n",
        "inputs = [\n",
        "    gr.components.Textbox(label=\"Enter Query (e.g., Search for ETF SPY)\", placeholder=\"Type your query here\"),\n",
        "    gr.components.Textbox(label=\"Fund Category (e.g., Large Blend)\", placeholder=\"e.g., Large Blend\"),\n",
        "    gr.components.Slider(0.0, 1.0, label=\"Minimum Yield (e.g., 0.01 for 1%)\"),\n",
        "    gr.components.Slider(0.0, 1.0, label=\"Minimum 1-Year Return (e.g., 0.1 for 10%)\"),\n",
        "    gr.components.Textbox(label=\"Top Holdings (e.g., Apple)\", placeholder=\"e.g., Apple\"),\n",
        "    gr.components.Textbox(label=\"Size Type (e.g., Large)\", placeholder=\"e.g., Large\"),\n",
        "    gr.components.Textbox(label=\"Region (e.g., US)\", placeholder=\"e.g., US\"),\n",
        "    gr.components.Slider(0.0, 1.0, label=\"Minimum 3-Year Return\"),\n",
        "    gr.components.Slider(0.0, 1.0, label=\"Minimum Sharpe Ratio (5 Years)\")\n",
        "]\n",
        "\n",
        "# Step 9: Create the Gradio interface\n",
        "outputs = gr.components.Dataframe(label=\"Filtered ETFs/Generated Text\")\n",
        "\n",
        "# Step 10: Launch the Gradio interface\n",
        "gr.Interface(fn=query_etfs, inputs=inputs, outputs=outputs, title=\"ETF and Mutual Fund Search App\").launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "MM1OeBpX9V9R",
        "outputId": "683225e6-50e2-44a3-80fd-94e239439178"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://77b8981de9ff1619c6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://77b8981de9ff1619c6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}